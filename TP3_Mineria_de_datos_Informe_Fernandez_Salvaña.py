# -*- coding: utf-8 -*-
"""TP3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WX_TGayx3TsXwyZN1hw2OrjgO0NS4mPp

# Trabajo Práctico N° 3
El objetivo de este trabajo practico es integrar los conocimientos adquiridos en las unidades 5 y 6 en un problema real asociado a la determinación del color de los granos de café mediante la
medición atributos característicos.

### Integrantes:
- Fernández, Florencia
- Salvañá, Leandro

Se importan las librerías necesarias
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pylab as pl
import plotly.express as px
import pprint as pp
from matplotlib.colors import ListedColormap
from sklearn import decomposition
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.utils import shuffle
from sklearn.metrics import confusion_matrix, classification_report, make_scorer
from sklearn.metrics import PredictionErrorDisplay, RocCurveDisplay, get_scorer_names, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, roc_auc_score, auc
from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelBinarizer, LabelEncoder
from mlxtend.plotting import plot_decision_regions
from sklearn.inspection import DecisionBoundaryDisplay
from imblearn.over_sampling import SMOTE
from collections import OrderedDict
from sklearn.metrics import hinge_loss
import plotly.express as px
from sklearn import decomposition
from sklearn.decomposition import PCA

import os
import warnings
warnings.filterwarnings('ignore')


"""  ----------------------------------
     ----------------------------------
              1- Introducción
     ----------------------------------
     ----------------------------------
"""
"""
Este informe se enfoca en aplicar técnicas de análisis de datos y aprendizaje supervisado
 para resolver un problema práctico relacionado con las calificaciones y colores en los granos de café. 
 Las actividades incluyen análisis de datos, estandarización, implementación de validación cruzada, 
 uso de modelos de clasificación como Support Vector Machine y RandomForest, optimización de hiper parámetros
   y comparación de desempeños obtenidos. Estas técnicas se aplican con el objetivo de obtener 
   los mejores modelos posibles para clasificar los granos de café por color de manera efectiva 
   según las calificaciones asignadas en diferentes características propias del grano.
"""



"""  ----------------------------------
     ----------------------------------
      2 - Análisis Exploratorio (EDA)
     ----------------------------------
     ----------------------------------
"""
"""
Se comenzará haciendo un análisis exploratorio del dataset 
para conocer sus características principales y evaluar si es necesario hacer algún 
manejo de datos faltantes, outliers, codificar variables categóricas, o algún otro 
proceso antes de comenzar.

### 2.1 - Importar el dataset y visualizar el dataframe
"""

coffee_ratings_df = pd.read_csv('CoffeeRatings.csv', sep = ';')
coffee_ratings_df.head()

"""Contexto:

Los datos provienen de Coffee Quality Database, cortesía del científico de datos de Buzzfeed, 
[James LeDoux](https://github.com/jldbc/coffee-quality-database).

Estos datos fueron recopilados de las páginas de revisión del 
Coffee Quality Institute en enero de 2018.

Hay datos tanto para los granos de Arábica como de Robusta, 
en muchos países y calificados profesionalmente en una escala de 0 a 100. 
Todo tipo de puntuaciones/calificaciones para características como acidez, dulzura, 
fragancia, equilibrio, etc.

Descripción de las columnas:

- Scores_Aroma: Tipo de dato: Float.	Aroma. Rango de puntuación: 0-10

  Fragancia/Aroma | Los aspectos aromáticos incluyen Fragancia (definida como el olor 
  del café molido cuando aún está seco) y Aroma (el olor del café cuando se infunde con 
  agua caliente). Se puede evaluar esto en tres pasos distintos en el proceso de cata: (1) 
  oler los sedimentos colocados en la taza antes de verter agua sobre el café; (2) oler los 
  aromas que se desprenden al romper la corteza; y (3) oler los aromas que se liberan a medida
    que el café se macera. Los aromas específicos se pueden anotar en "cualidades" y la intensidad
      de los aspectos de aroma seco, quebrado y húmedo se anotan en las escalas verticales de 5 puntos. 
      La puntuación finalmente otorgada debe reflejar la preferencia de los tres aspectos de la 
      fragancia/aroma de una muestra.

- Scores_Flavor:	Tipo de dato: Float.	Flavor. Rango de puntuación: 0-10

  Sabor | El sabor representa el carácter principal del café, las notas "medias", 
  desde las primeras impresiones que da el primer aroma y la acidez del café hasta su retrogusto final. 
  Es una impresión combinada de todas las sensaciones gustativas (papilas gustativas) y 
  aromas retronasales que van de la boca a la nariz. La puntuación otorgada al Sabor debe tener 
  en cuenta la intensidad, la calidad y la complejidad de su sabor y aroma combinados, 
  experimentados cuando el café se sorbe vigorosamente en la boca para involucrar a todo el 
  paladar en la evaluación.

- Scores_Aftertaste:	Tipo de dato: Float.	Aftertaste. Rango de puntuación: 0-10

  Regusto | El regusto se define como la duración de las cualidades positivas de sabor 
  (sabor y aroma) que emanan de la parte posterior del paladar y que quedan después de 
  expectorar o tragar el café. Si el regusto fuera breve o desagradable, se daría una puntuación más baja.

- Scores_Acidity:	Tipo de dato: Float.	Acidity. Rango de puntuación: 0-10

  Acidez | La acidez a menudo se describe como "brillo" cuando es favorable o "ácida" 
  cuando es desfavorable. En el mejor de los casos, la acidez contribuye a la vivacidad, 
  la dulzura y el carácter de fruta fresca del café y se experimenta y evalúa casi de inmediato 
  cuando el café se sorbe por primera vez en la boca. Sin embargo, una acidez demasiado intensa o 
  dominante puede resultar desagradable y una acidez excesiva puede no ser apropiada para el perfil 
  de sabor de la muestra. La puntuación final marcada en la escala horizontal debe reflejar la 
  calidad percibida por el panelista para la acidez en relación con el perfil de sabor esperado 
  en función de las características de origen y/u otros factores (grado de tueste, uso previsto, etc.). 
  Los cafés que se espera que tengan una acidez alta, como el café de Kenia, o los cafés que se espera 
  que tengan una acidez baja, como el café de Sumatra, pueden recibir puntuaciones de preferencia 
  igualmente altas, aunque sus clasificaciones de intensidad serán bastante diferentes.

- Scores_Body:	Tipo de dato: Float.	Body. Rango de puntuación: 0-10

  Cuerpo | La calidad del cuerpo se basa en la sensación táctil del líquido en la boca, 
  especialmente cuando se percibe entre la lengua y el paladar. La mayoría de las muestras 
  con cuerpo pesado también pueden recibir una puntuación alta en términos de calidad debido a 
  la presencia de coloides y sacarosa. Sin embargo, algunas muestras con cuerpo más claro también 
  pueden tener una sensación agradable en la boca. Los cafés que se espera que tengan un alto 
  contenido de cuerpo, como el café de Sumatra, o los cafés que se espera que tengan un bajo 
  contenido de cuerpo, como el café mexicano, pueden recibir puntuaciones de preferencia 
  igualmente altas, aunque sus clasificaciones de intensidad serán bastante diferentes.

- Scores_Balance:	Tipo de dato: Float.	Balance. Rango de puntuación: 0-10

  Balance | La forma en que todos los diversos aspectos de sabor, regusto, acidez y cuerpo
    de la muestra trabajan juntos y se complementan o contrastan entre sí es el equilibrio. 
    Si a la muestra le faltan ciertos atributos de aroma o sabor o si algunos atributos 
    son abrumadores, la puntuación de equilibrio se reducirá.

- Scores_Uniformity:	Tipo de dato: Float.	Uniformity. Rango de puntuación: 0-10

  Uniformidad | La uniformidad se refiere a la consistencia del sabor de las diferentes
   tazas de la muestra degustada. Si las tazas tuvieran un sabor diferente, la valoración de 
   este aspecto no sería tan alta. Se otorgan 2 puntos por cada copa que muestre este atributo,
   con un máximo de 10 puntos si las 5 copas son iguales.

- Scores_Sweetness:	Tipo de dato: Float.	Sweetness. Rango de puntuación: 0-10

  Dulzura | El dulzor se refiere a una agradable plenitud de sabor, así como a cualquier 
  dulzor evidente, y su percepción es el resultado de la presencia de ciertos carbohidratos. 
  Lo opuesto al dulzor en este contexto son los sabores ácidos, astringentes o "verdes". 
  Es posible que esta cualidad no se perciba directamente como en productos cargados de sacarosa, 
  como los refrescos, pero afectará otros atributos de sabor. Se otorgan 2 puntos por 
  cada copa que muestre este atributo para una puntuación máxima de 10 puntos.

- Scores_Moisture:	Tipo de dato: Float.	Moisture. Rango de puntuación: 0%-100%

  Nivel de humedad en el grano de café.

- Scores_Total:	Tipo de dato: Float.	Total score. Rango de puntuación: 0-100

  Puntaje total asignado como valorización del grano de café.

  Clasificación de calidad de puntuación total:

  - 90-100 - Sobresaliente - Especialidad
  - 85-99.99 - Excelente - Especialidad
  - 80-84.99 - Muy bueno - Especialidad
  - < 80,0 - Calidad inferior a la de especialidad - No especialidad

- Color:	Tipo de dato: String.	Color del grano

Las fuentes que se utilizaron para:
- Descripción de las características/columnas del dataframe corresponde a: 
[Specialty Coffee Association](https://sca.coffee/research/protocols-best-practices)

- Tipo de dato adecuado para cada columna y rangos corresponde a: 
[Coffee Quality Institute](https://database.coffeeinstitute.org/coffee/654175)


Es de dichos sitios web de donde se han obtenido los datos según lo indicado por el 
creador del dataset en su repositorio.
"""

"""
#### 2.1.1 - Corrección de la escala y el tipo de dato de las columnas

Por lo detallado anteriormente, se hace evidente que se deben realizar las operaciones
 sobre las columnas a fin de obtener los datos en los rangos adecuados y el tipo de dato correcto.
"""

# Obtener las columnas numéricas
columnas_numericas = coffee_ratings_df.select_dtypes(include=['float64', 'int64']).columns

# Excluir la columna 'Scores_Moisture' de las columnas a dividir por 100
columnas_numericas = columnas_numericas.difference(['Scores_Moisture'])

# Dividir todas las columnas numéricas (excepto 'Scores_Moisture') por 100
coffee_ratings_df[columnas_numericas] /= 100

print(coffee_ratings_df.head())

# Se averiguan la cantidad de filas y columnas en el dataset
print(coffee_ratings_df.shape)

"""El dataset posee 835 filas de observaciones y 11 variables para describir el grano de café.
"""

"""
### 2.2 - Conocer las columnas

#### 2.2.1 - Se imprime una lista de las columnas con sus respectivos tipos y cantidad de datos.
"""

print(coffee_ratings_df.info())

# Se comprueba si existen valores nulos en las columnas del dataset
print(coffee_ratings_df.isna().sum())

"""Se observa que no hay presencia de valores faltantes y que el tipo de dato especificado para cada columna se corresponde con lo que representan. Excepto por la columna Scores_Moisture que debería ser tipo float.

Por lo divisado, no será requerido completar valores faltantes en el dataset y realizar solo un cambio en el tipo de dato de la columnas Scores_Moisture.
"""

# Tipo de dato int a float para la columna 'Scores_Moisture'
coffee_ratings_df['Scores_Moisture'] *= 1.0

print(coffee_ratings_df.info())


"""#### 2.2.2 - Observar la variable 'Color'"""

# Se quiere conocer qué colores fueron asignados para formar este dataset
unique_labels = coffee_ratings_df['Color'].unique()
print("Valores únicos en la columna 'Color':")
count = 0
for label in unique_labels:
    print(f'- {label}')
    count += 1
print('\n')
print(f'Cantidad de valores únicos en la columna color: {count}')

# Se observa la cantidad de filas presentes para cada color
print(coffee_ratings_df.Color.value_counts())

"""Se observa que existe un desbalance entre la cantidad de granos de cada color en el dataset.
"""

"""
#### 2.2.3 - Se analizará si existen valores en las columnas que se encuentren fuera de rango en relación con la característica que representan.
"""

# Se comprueba si existen valores negativos para las columnas
for column in coffee_ratings_df.select_dtypes(include=['float64', 'int64']).columns.tolist():
  print(f'Columna {column}')
  print(coffee_ratings_df.loc[(coffee_ratings_df[column] < 0)])

# Se comprueba si existen valores mayores a 10 para las columnas
columnas_rango_0_a_10 = columnas_numericas.difference(['Scores_Total'])
for column in columnas_rango_0_a_10.tolist():
  print(f'Columna {column}')
  print(coffee_ratings_df.loc[coffee_ratings_df[column] > 10])

# Se comprueba si existen valores mayores a 100 para las columnas Scores_Moisture y Scores_Total
for column in ['Scores_Moisture', 'Scores_Total']:
  print(f'Columna {column}')
  print(coffee_ratings_df.loc[(coffee_ratings_df[column] > 100)])

"""No se observa presencia de registros con valores inadecuados para las variables representadas en las columnas del dataset.
"""

"""
### 2.3 - Medidas estadísticas y de localización
En este paso se estudian, para cada columna, medidas de localización como mínimo, máximo, cuartiles, y de centralidad como la mediana y la media.

 Estas mediciones proporcionan una visión resumida de la distribución de los datos. Esto puede aportar valiosa información para el análisis e interpretación de los datos de puntuación de cada atributo y su relación con el color del grano.
"""

# Se obtienen medidas estadísticas para el dataset completo
print(coffee_ratings_df.describe())

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.3. Medidas estadísticas y de localización"""
"""************************************************************************************************"""

"""
### 2.4 - Visualización de la distribución mediante gráficos y matriz de correlación

#### 2.4.1 - Proporción de granos de cada color
"""

# Configuración de subplots
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))

# Calcular las proporciones de cada color
proporciones = coffee_ratings_df['Color'].value_counts(normalize=True)

# Gráfico de barras
ax1 = axes[1]
sns.countplot(x='Color', data=coffee_ratings_df, palette=['lightgreen', 'skyblue', 'lightcoral'])
ax1.set_xlabel('Color grano de café')
ax1.set_ylabel('Cantidad')
ax1.set_title('Cantidad de granos de café por color')
ax1.tick_params(axis='x', rotation=80)

# Gráfico de tortas
ax2 = axes[0]
ax2.pie(proporciones, labels=proporciones.index, autopct='%1.1f%%', colors=['lightgreen', 'lightcoral', 'skyblue'])
ax2.set_title('Porcentaje de granos de café por color', y=1.21)

plt.tight_layout()
plt.show(block=True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.1. Proporción de granos de cada color"""
"""************************************************************************************************"""



"""
#### 2.4.2 - Distribución de los datos

Los gráficos a continuación combinan una representación de la distribución de datos (el violinplot) con datos brutos dispersos (scatter plot) y se complementan aún más añadiendo boxplots.
"""

# Obtener listas de características
data_x = []
scores_columns = coffee_ratings_df.select_dtypes(include=['float64', 'int64']).columns.tolist()
for column in scores_columns:
  xi = coffee_ratings_df[column].values
  data_x.append(xi)

# Crear un diccionario de mapeo de colores a números
mapeo_colores = {'Green': 1,
                 'Bluish-Green': 2,
                 'Blue-Green': 3}

# Aplicar el mapeo a la columna 'Color' y crear un nuevo array
array_resultado = coffee_ratings_df['Color'].map(mapeo_colores).values

# Color boxplot
boxplots_colors = ['#ff9b73']
# Color scatter
scatter_colors = ['#96787a']
# Colores violin plots
colors_plot = ['#003bda', '#c71cd2', '#da2159', '#c5b3f5', '#a688ed', '#319600', '#00b397', '#e99a00', '#c11847', '#ff6d90']
# Crear subplots
fig, axes = plt.subplots(len(scores_columns), 1, figsize=(10, 35), sharex=False)

# Generar boxplots horizontales para cada columna en la clase grapes
for i, col in enumerate(scores_columns):
  # Dibujar scatter plot
  y = np.full(len(data_x[i]), 1.8) + np.random.uniform(low=-.05, high=.05, size=len(data_x[i]))
  classes = ['Green', 'Bluish-Green', 'Blue-Green']
  values = array_resultado
  colors = ListedColormap(['#8f64d3','#db8070','#dba139'])
  scatter_g = axes[i].scatter(data_x[i], y, s=10, c=values, cmap=colors)
  axes[i].legend(handles=scatter_g.legend_elements()[0], labels=classes, loc='lower left')


  # Boxplot data
  bp = axes[i].boxplot(data_x[i], patch_artist = True, vert = False, meanline=True, showmeans=True,
                       medianprops={'color': '#9c4aa8', 'visible': True}, meanprops={'color': '#4c891c', 'visible': True})

  for patch, color in zip(bp['boxes'], boxplots_colors):
      patch.set_facecolor(boxplots_colors[0])
      patch.set_alpha(0.4)

  ax2 = axes[i].twinx()
  for sty in [('Media', '#4c891c'), ('Mediana', '#9c4aa8')]:
      ax2.plot(np.NaN, np.NaN, label=sty[0], c=sty[1])
  ax2.get_yaxis().set_visible(False)

  ax2.legend(loc='lower right')
  # Violinplot data
  vp = axes[i].violinplot(data_x[i], points=500,
                showmeans=True, showextrema=False, showmedians=True, vert=False)

  for idx, b in enumerate(vp['bodies']):
      # Modificarlo para ver solo la mitad superior del gráfico
      b.get_paths()[0].vertices[:, 1] = np.clip(b.get_paths()[0].vertices[:, 1], idx+1, idx+2)
      # Cambiar al color deseado
      b.set_color(colors_plot[i])

  axes[i].set_title(f'Plot de {col}')
  axes[i].set_xlabel('Values')
  axes[i].set_ylabel(col)

# Ajustar espaciado entre subplots
plt.tight_layout()

# Mostrar los gráficos
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.2. Distribución de los datos"""
"""************************************************************************************************"""



"""
#### 2.4.3 - Histogramas

Se realizarán histogramas para observar en más detalle la distribución bimodal y las frecuencias en los valores registrados
"""

# Configura el tamaño de la figura
plt.figure(figsize=(12, 10))

# Itera a través de cada columna numérica y crea un histograma (excluyendo 'Color')
for i, column in enumerate(scores_columns):
    plt.subplot((len(scores_columns) + 1)//2, 2, i+1)  # Divide la figura en subplots
    sns.histplot(coffee_ratings_df[column], color=colors_plot[i], kde=True)  # Crea el histograma
    plt.title(f'Histograma de {column}')
    plt.xlabel(column)
    plt.ylabel('Frecuencia')

# Ajusta el espacio entre subplots
plt.tight_layout()

# Muestra los gráficos
plt.show(block=True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.3. Histogramas"""
"""************************************************************************************************"""


"""
- Se observará la distribución de los histogramas por color de grano.

Se utilizará un límite de altura para el eje vertical ya que lo que se busca analizar aqui no es la frecuencia, sino observar si existen ciertos rangos en los valores de las variables para los cuales se hallan granos de un color y no de otro. Esta observación en detalle, podría indicar posibles formas de diferenciar la clase de grano según valores en las demás características.
"""

# Configura el tamaño de la figura
plt.figure(figsize=(10, 24))

# Itera a través de cada columna numérica y crea un histograma (excluyendo 'Color')
for i, column in enumerate(scores_columns):
    plt.subplot((len(scores_columns) + 1)//2, 2, i+1)  # Divide la figura en subplots
    sns.histplot(data=coffee_ratings_df, x=column, hue='Color', bins=15, multiple="dodge", palette= ['lightgreen', 'skyblue', 'lightcoral'])
    plt.title(f'Histograma de {column} según color de grano')
    plt.xlabel(column)
    plt.ylabel('Frecuencia')
    # Ajustar el rango del eje y
    plt.ylim(0, 35)


# Ajusta el espacio entre subplots
plt.tight_layout()

# Muestra los gráficos
plt.show(block=True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.3. Histogramas"""
"""************************************************************************************************"""


# Paleta de colores
colors = ListedColormap(['#8f64d3','#db8070','#dba139'])
# Box plot por clase para variables seleccionadas
for feature in scores_columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x='Color', y=feature, data=coffee_ratings_df, palette=['lightgreen', 'skyblue', 'lightcoral'])
    plt.title(f'Box Plot de {feature} por Clase')
    plt.show(block=True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.3. Histogramas"""
"""************************************************************************************************"""


"""
#### 2.4.4 - Matriz de correlación
"""

# Calcular la matriz de correlación
correlation_matrix = coffee_ratings_df.drop('Color', axis=1).corr()

# Crear un mapa de calor (correlograma)
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap='rocket', annot=True, fmt=".2f", linewidths=0.5)
plt.title('Correlograma de Todas las Columnas')
plt.show(block=True)

sns.pairplot(coffee_ratings_df.drop('Color', axis=1), plot_kws = {'color': '#a688ed', 'marker': 'p'},
             diag_kws = {'color': '#00b397'}, corner = True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.4. Matriz de correlación"""
"""************************************************************************************************"""



"""
### 2.5 - División del dataset y estandarización de los datos
"""

# X son las variables independientes y 'Color' es la variable dependiente
X = coffee_ratings_df.drop('Color', axis=1)
y = coffee_ratings_df['Color']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar y ajustar el StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)



"""  ----------------------------------------------
     ----------------------------------------------
        3 - Clasificación con SVM y kernel lineal
     ----------------------------------------------
     ----------------------------------------------
"""
"""Realizar la predicción del atributo Color utilizando máquinas de vectores con kernel lineal
analizando el parámetro costo. Mostar los resultados sobre los conjuntos de test
(Precisión, Exhaustividad y Exactitud) utilizando validación cruzada con k =5.
"""

"""
### 3.1 - Definición y fit del modelo
"""

# Definición del Modelo
svm_classifier_linear = SVC(kernel='linear', C=10, random_state=42, probability=True)

# Entrenamiento
svm_classifier_linear.fit(X_train_scaled, y_train)

"""### 3.2 - Cross validation para SVM con kernel lineal
"""
"""************************************************************************************************"""
"""Explicaciones pertinentes redactadas en el informe en la sección 3.2. Cross validation para SVM con kernel lineal"""
"""************************************************************************************************"""

svm_linear = SVC(kernel='linear', C=10, random_state=42)
n_splits = 5
# Estrategia para obtener los folds
cv = StratifiedKFold(n_splits=n_splits)

"""Se utiliza StratifiedKFold debido a la existencia de desbalance de clases.

StratifiedKFold es una variación de k-fold que devuelve pliegues estratificados: cada set contiene aproximadamente el mismo porcentaje de muestras de cada clase objetivo que el set completo.
"""

# Realizar cross-validation y almacenar coeficientes
for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train)):
      index_labels = y_train.index
      dfX_train_scaled = pd.DataFrame(X_train_scaled, index=index_labels)
      X_train_fold, X_val = dfX_train_scaled.iloc[train_index], dfX_train_scaled.iloc[test_index]
      y_train_fold, y_val = y_train.iloc[train_index], y_train.iloc[test_index]

      # Entrenar el modelo en el conjunto de entrenamiento y obtener los coeficientes
      svm_linear.fit(X_train_fold, y_train_fold)

      pred = svm_linear.predict(X_val)
      print(f'Classification report para el split {i} de la validación cruzada')
      print(classification_report(y_val, pred))
      cm = confusion_matrix(y_val, pred)
      # Visualizar la matriz de confusión con Seaborn
      sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
                  xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
      plt.xlabel('Predicción')
      plt.ylabel('Real')
      plt.title('Matriz de Confusión CV de SVC kernel lineal')
      plt.show(block=True)

      print('\n')

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 2.4.4. Matriz de correlación"""
"""************************************************************************************************"""

"""
A continuación, se entrenará el modelo inicialmente definido con todos los datos de training y se testeará con el correspondiente set de test reservado para tal fin. Luego, se realizarán las observaciones pertinentes.
"""

"""
### 3.3 - Entrenamiento del modelo, predicciones, gráficos y análisis
"""

pred_test = svm_classifier_linear.predict(X_test_scaled)

print(f'Classification report')
print(classification_report(y_test, pred_test))
cm = confusion_matrix(y_test, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de SVC kernel lineal')
plt.show(block=True)

classes_list = svm_classifier_linear.classes_.tolist()
coefs_ = svm_classifier_linear.coef_.tolist()
coefs_list = [[round(elemento, 4) for elemento in sublista] for sublista in coefs_]
rows_coef_df = [[classes_list[0]] + coefs_list[2], [classes_list[1]] + coefs_list[1], [classes_list[2]] + coefs_list[0] ]
columns_coef = scores_columns.copy()
columns_coef_df = ['Color'] + [f'Coef_{elemento}' for elemento in columns_coef]
coef_df = pd.DataFrame(rows_coef_df, columns=columns_coef_df)

print('\n Dataframe de los valores de coeficientes asignados a cada feature por el modelo \n')
print(coef_df)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 3.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Métricas y matriz de confusión:"""
"""************************************************************************************************"""



"""
Para el siguiente gráfico ilustrativo en 2D se utilizarán las variables con mayores coeficientes asignados (Scores_Acidity y Scores_Balance)
"""
# Usamos un encoder para poder realizar el siguiente gráfico. Ya que precisa que sean valores numéricos
encoder = LabelEncoder()

y_train_encoded = encoder.fit_transform(y_train)
y_test_encoded = encoder.transform(y_test)

X_train_graph_scaled = X_train_scaled[:,[3, 5]]
X_test_graph_scaled = X_test_scaled[:,[3, 5]]

svm_classifier_linear.fit(X_train_graph_scaled, y_train_encoded)

fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

pred_grid = svm_classifier_linear.predict(grid)

z=svm_classifier_linear.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=svm_classifier_linear, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7})

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de SVC kernel lineal')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 3.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Gráfico de regiones de clase:"""
"""************************************************************************************************"""



"""
#### 3.3.1 - Uso de reducción de la dimensionalidad para observar distribución de los datos

Adicionalmente y, a modo exploratorio, se realizará un gráfico tridimensiional de los datos con sus respectivas clases para tener un acercamiento visual sobre cómo se distribuyen los datos en el espacio.
"""

# Realiza el PCA en los datos estandarizados
pca = PCA(n_components=X_train_scaled.shape[1])
principal_components = pca.fit_transform((np.concatenate((X_train_scaled, X_test_scaled), axis=0)))

# Variabilidad explicada por cada componente principal
explained_variance_ratio = pca.explained_variance_ratio_

# Calcular la proporción acumulada de varianza explicada
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)

# Crear un DataFrame con las columnas requeridas
pca_exp_var_df = pd.DataFrame({
    "Eigenvalues": principal_components.var(axis=0),  # Varianza explicada por cada componente principal
    "Proporción de varianza explicada": explained_variance_ratio,
    "Proporción acumulada de varianza explicada": cumulative_variance_ratio
})

pca_exp_var_df

# Columns for PCA dataframe
pc_columns = [f'PC{i}' for i in range(1, len(X_train.columns) + 1)]

# PC dataframe
pca_df = pd.DataFrame(
    data=principal_components,
    columns=pc_columns)
pca_df['Color'] = coffee_ratings_df['Color']

fig = px.scatter_3d(principal_components, x=0, y=1, z=2,
              color=pca_df["Color"],  labels={'color': 'Color'})
fig.show(block=True)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 3.3.1. Uso de reducción de la dimensionalidad para observar distribución de los datos"""
"""************************************************************************************************"""



"""
### 3.4 Tuning de hiperparámetros para el modelo con kernel lineal

Dado que el modelo tiene un desempeño desalentador para realizar clasificaciones de los granos de café de manera correcta. O, mejor dicho, dado que el modelo indicará que la clase a la que pertenece el grano es Green, acertando en muchos casos, pero errando en muchos otros debido al entrenamiento con un fuerte desbalance de clases y dificultad para distinguir la separación de las mismas, se buscará mejorar el hiperparámetro C del mismo con el fin flexibilizar el margen que separa las regiones de clases para intentar aproximar el modelo a una mejora en el desempeño.
"""

# Definición de un modelo clasificador de Random Forest
svm_lineal_classifier = SVC()

# Parámetros del Gridsearch
params_grid = [{'kernel': ['linear'], 'C': [1, 10, 100, 200], 'random_state': [42]}]

# Configurar la búsqueda grid con validación cruzada (cross-validation)
grid_search = GridSearchCV(estimator=svm_lineal_classifier, param_grid=params_grid, scoring = ['accuracy', 'precision_macro', 'recall_macro'], refit='accuracy',
                           cv=cv)

# Realizar la búsqueda grid en el conjunto de entrenamiento
grid_search.fit(X_train_scaled, y_train)

# Obtener los mejores hiperparámetros encontrados
best_params = grid_search.best_params_
print('Mejores hiperparámetros de SVC kernel lineal:', best_params)

"""Se observa que el mejor hiperparámetro hallado es C=1, es decir, el que busca ampliar más el margen.
"""

"""
A continuación se evaluará el rendimiento del modelo usando el mejor estimador hallado.
"""

best_estimator_svc_lineal = grid_search.best_estimator_
best_estimator_svc_lineal.fit(X_train_scaled, y_train)
pred_test = best_estimator_svc_lineal.predict(X_test_scaled)

print(f'Classification report')
print(classification_report(y_test, pred_test))
cm = confusion_matrix(y_test, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de SVC kernel lineal con mejores parámetros hallados')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 3.4. Tuning de hiperparámetros para el modelo con kernel lineal
Métricas y matriz de confusión:
"""
"""************************************************************************************************"""


fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

best_estimator_svc_lineal.fit(X_train_graph_scaled, y_train_encoded)
pred_grid = best_estimator_svc_lineal.predict(grid)

z=best_estimator_svc_lineal.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=best_estimator_svc_lineal, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7}, X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de SVC kernel lineal con mejores parámetros hallados')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 3.4. Tuning de hiperparámetros para el modelo con kernel lineal
Gráfico de regiones de clase:
"""
"""************************************************************************************************"""




"""  ----------------------------------------------
     ----------------------------------------------
      4 - Clasificación con SVM y kernel gaussiano
     ----------------------------------------------
     ----------------------------------------------
"""
"""
Realizar la predicción del atributo Color utilizando máquinas de vectores con kernel
gaussiano analizando los parámetros costo y gama. Mostar los resultados sobre los
conjuntos de test (Precisión, Exhaustividad y Exactitud) utilizando validación cruzada con
k =5.
"""

"""
### 4.1 - Definición y fit del modelo
"""
# Definición del Modelo
svm_classifier_gaussiano = SVC(kernel='rbf', C=10, random_state=42, probability=True)

# Entrenamiento
svm_classifier_gaussiano.fit(X_train_scaled, y_train)

"""### 4.2 - Cross validation para SVM con kernel gaussiano"""

svm_gaussiano = SVC(kernel='rbf', C=10, random_state=42)
n_splits = 5
# Estrategia para obtener los folds
cv = StratifiedKFold(n_splits=n_splits)

# Realizar cross-validation y almacenar coeficientes
for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train)):
      index_labels = y_train.index
      dfX_train_scaled = pd.DataFrame(X_train_scaled, index=index_labels)
      X_train_fold, X_val = dfX_train_scaled.iloc[train_index], dfX_train_scaled.iloc[test_index]
      y_train_fold, y_val = y_train.iloc[train_index], y_train.iloc[test_index]

      # Entrenar el modelo en el conjunto de entrenamiento y obtener los coeficientes
      svm_gaussiano.fit(X_train_fold, y_train_fold)

      pred = svm_gaussiano.predict(X_val)
      print(f'Classification report para el split {i} de la validación cruzada')
      print(classification_report(y_val, pred))
      cm = confusion_matrix(y_val, pred)
      # Visualizar la matriz de confusión con Seaborn
      sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
                  xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
      plt.xlabel('Predicción')
      plt.ylabel('Real')
      plt.title('Matriz de Confusión para CV de SVC kernel gaussiano')
      plt.show(block=True)

      print('\n')

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.2. Cross validation para SVM con kernel gaussiano
"""
"""************************************************************************************************"""



"""
A continuación, se entrenará el modelo inicialemnte definido con todos los datos de training y se testeará con el correspondiente set de test reservado para tal fin. Luego, se realizarán las observaciones pertinentes.
"""


"""
### 4.3 - Entrenamiento del modelo, predicciones, gráficos y análisis
"""
pred_test = svm_classifier_gaussiano.predict(X_test_scaled)

print(f'Classification report')
print(classification_report(y_test, pred_test))
cm = confusion_matrix(y_test, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de SVC kernel gaussiano')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Métricas y matriz de confusión:
"""
"""************************************************************************************************"""



fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

svm_classifier_gaussiano.fit(X_train_graph_scaled, y_train_encoded)
pred_grid = svm_classifier_gaussiano.predict(grid)

z=svm_classifier_gaussiano.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=svm_classifier_gaussiano, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7}, X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de SVC kernel gaussiano')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Gráfico de regiones de clase:
"""
"""************************************************************************************************"""




"""
### 4.4 - Tuning de hiperparámetros para el modelo con kernel gaussiano

Dado que el modelo tiene un desempeño desalentador para realizar clasificaciones de los granos de café de manera correcta. O, mejor dicho, dado que el modelo indicará que la clase a la que pertenece el grano es Green la mayoría de las veces, acertando en muchos casos, pero errando en muchos otros debido al entrenamiento con un fuerte desbalance de clases y dificultad para distinguir la separación de las mismas, se buscará mejorar el hiperparámetro C y gamma del mismo con el fin flexibilizar el margen que separa las regiones de clases para intentar aproximar el modelo a una mejora en el desempeño.
"""

# Definición de un modelo clasificador de Random Forest
svm_gaussian_classifier = SVC()

# Parámetros del Gridsearch
params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1, 10, 100],
                'C': [1, 10, 100, 200]}]

# Configurar la búsqueda grid con validación cruzada (cross-validation)
grid_search = GridSearchCV(estimator=svm_gaussian_classifier, param_grid=params_grid, scoring = ['accuracy', 'precision_macro', 'recall_macro'], refit='accuracy',
                           cv=cv)

# Realizar la búsqueda grid en el conjunto de entrenamiento
grid_search.fit(X_train_scaled, y_train)

# Obtener los mejores hiperparámetros encontrados
best_params = grid_search.best_params_
print('Mejores hiperparámetros de SVC kernel gaussiano:', best_params)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.4. Tuning de hiperparámetros para el modelo con kernel gaussiano
"""
"""************************************************************************************************"""



"""
A continuación se evaluará el rendimiento del modelo usando el mejor estimador hallado.
"""
best_estimator_gaussian_svc = grid_search.best_estimator_
best_estimator_gaussian_svc.fit(X_train_scaled, y_train)
pred_test = best_estimator_gaussian_svc.predict(X_test_scaled)

print(f'Classification report')
print(classification_report(y_test, pred_test))
cm = confusion_matrix(y_test, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de SVC kernel gaussiano para los mejores hiperparámetros hallados')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.4. Tuning de hiperparámetros para el modelo con kernel gaussiano
Métricas y matriz de confusión:
"""
"""************************************************************************************************"""



fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

best_estimator_gaussian_svc.fit(X_train_graph_scaled, y_train_encoded)
pred_grid = best_estimator_gaussian_svc.predict(grid)

z=best_estimator_gaussian_svc.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=best_estimator_gaussian_svc, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7}, X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de SVC kernel gaussiano para los mejores hiperparámetros hallados')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 4.4. Tuning de hiperparámetros para el modelo con kernel gaussiano
Gráfico de regiones de clase:
"""
"""************************************************************************************************"""




"""  ----------------------------------------------
     ----------------------------------------------
          5 - Clasificación con Random Forest
     ----------------------------------------------
     ----------------------------------------------
"""
"""
Realizar la predicción del atributo Color utilizando Random Forest analizando los
parámetros cantidad de estimadores y la máxima profundidad de los árboles. Mostar los
resultados sobre los conjuntos de test (Precisión, Exhaustividad y Exactitud) utilizando
validación cruzada con k =5.
"""

"""
### 5.1 - Definición y fit del modelo
"""

rf = RandomForestClassifier(n_estimators=150,
                            max_depth=5,
                            max_features='sqrt',
                            random_state=42
                            )

random_forest  = rf.fit(X_train_scaled, y_train)

"""### 5.2 - Cross validation para Random Forest"""

rfc = RandomForestClassifier(n_estimators=150,
                            max_depth=5,
                            max_features='sqrt',
                            random_state=42
                            )
n_splits = 5
# Estrategia para obtener los folds
cv = StratifiedKFold(n_splits=n_splits)

# Realizar cross-validation y almacenar coeficientes
for i, (train_index, test_index) in enumerate(cv.split(X_train_scaled, y_train)):
      index_labels = y_train.index
      dfX_train_scaled = pd.DataFrame(X_train_scaled, index=index_labels)
      X_train_fold, X_val = dfX_train_scaled.iloc[train_index], dfX_train_scaled.iloc[test_index]
      y_train_fold, y_val = y_train.iloc[train_index], y_train.iloc[test_index]

      # Entrenar el modelo en el conjunto de entrenamiento y obtener los coeficientes
      rfc.fit(X_train_fold, y_train_fold)

      pred = rfc.predict(X_val)
      print(f'Classification report para el split {i} de la validación cruzada')
      print(classification_report(y_val, pred))
      cm = confusion_matrix(y_val, pred)
      # Visualizar la matriz de confusión con Seaborn
      sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
                  xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
      plt.xlabel('Predicción')
      plt.ylabel('Real')
      plt.title('Matriz de Confusión para CV de Random Forest')
      plt.show(block=True)

      print('\n')

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.2. Cross validation para Random Forest
"""
"""************************************************************************************************"""



"""
### 5.3 - Entrenamiento del modelo, predicciones, gráficos y análisis
"""
pred_test_rf = rfc.predict(X_test_scaled)

print(f'Classification report')
print(classification_report(y_test, pred_test_rf))
cm = confusion_matrix(y_test, pred_test_rf)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de Random Forest')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Métricas y matriz de confusión:
"""
"""************************************************************************************************"""


# Organizing feature names and importances in a DataFrame
features_df = pd.DataFrame({'features': scores_columns, 'importances': random_forest.feature_importances_ })

# Sorting data from highest to lowest
features_df_sorted = features_df.sort_values(by='importances', ascending=False)

# Barplot of the result without borders and axis lines
g = sns.barplot(data=features_df_sorted, x='importances', y ='features', palette="rocket")
sns.despine(bottom = True, left = True)
g.set_title('Feature importances - Random Forest')
g.set(xlabel=None)
g.set(ylabel=None)
g.set(xticks=[])
for value in g.containers:
    g.bar_label(value, padding=2)

"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Gráfico de barras de importancia de características en Random Forest:
"""
"""************************************************************************************************"""



fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

rfc.fit(X_train_graph_scaled, y_train_encoded)
pred_grid = rfc.predict(grid)

z=rfc.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

#plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=rfc, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7},
                      X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de Random Forest')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.3. Entrenamiento del modelo, predicciones, gráficos y análisis
Gráfico de regiones de clase:
"""
"""************************************************************************************************"""



"""
### 5.4 - Tuning de hiperparámetros para el modelo de Random Forest

Dado que el modelo tiene un desempeño aún bajo, pero mejora con respecto a los modelos anteriores para realizar clasificaciones de los granos de café, se buscará mejorar los hiperparámetros del mismo buscando una mejora en el desempeño.
"""

# Definición de un modelo clasificador de Random Forest
rf_classifier = RandomForestClassifier(random_state=42)

# Definir los hiperparámetros a ajustar y sus posibles valores
param_grid = {
    'n_estimators': [50, 100],
    'max_features': ['sqrt', 6],
    'max_depth': [30, 50],
    'random_state': [42],
    'class_weight': ['balanced_subsample', 'balanced'],
    'max_samples': [50, 100],
    'min_samples_leaf': [10, 20],
    'max_leaf_nodes': [300, 350, 100]
}

# Configurar la búsqueda grid con validación cruzada (cross-validation)
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring = ['accuracy', 'precision_macro', 'recall_macro'], refit='accuracy',
                           cv=cv)

# Realizar la búsqueda grid en el conjunto de entrenamiento
grid_search.fit(X_train_scaled, y_train)

# Obtener los mejores hiperparámetros encontrados
best_params = grid_search.best_params_
print('Mejores hiperparámetros:', best_params)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.4. Tuning de hiperparámetros para el modelo de Random Forest
"""
"""************************************************************************************************"""



best_estimator_rf = grid_search.best_estimator_
best_estimator_rf.fit(X_train_scaled, y_train)
pred_test = best_estimator_rf.predict(X_test_scaled)
print(f'Classification report')
print(classification_report(y_test, pred_test))
cm = confusion_matrix(y_test, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de Random Forest para los mejores hiperparámetros hallados')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.4. Tuning de hiperparámetros para el modelo de Random Forest
Métricas y matriz de confusión:
"""
"""************************************************************************************************"""



fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

best_estimator_rf.fit(X_train_graph_scaled, y_train_encoded)
pred_grid = best_estimator_rf.predict(grid)

z=best_estimator_rf.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_encoded, y_test_encoded), axis=0), clf=best_estimator_rf, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7}, X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de Random Forest para los mejores hiperparámetros hallados')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 5.4. Tuning de hiperparámetros para el modelo de Random Forest
Gráfico de regiones de clase:
"""
"""************************************************************************************************"""




"""  ---------------------------
     ---------------------------
          6 - Conclusiones
     ---------------------------
     ---------------------------
"""
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 6. Conclusiones"""
"""************************************************************************************************"""




"""  ---------------------------
     ---------------------------
             7 - Anexo
     ---------------------------
     ---------------------------
"""
"""
Se añade un anexo donde se analiza someramente la consideración anteriror con respecto al desbalance de clases y su influencia en el rendimiento de los modelos.

A continuación, se utilizará un modelo SVC con kernel  gaussiano, se entrenará el estimador sobre datos de entrenamiento con las clases balanceadas y se evaluarán las predicciones sobre los datos de test con dicho estimador.
"""

# Crear una instancia de SMOTE
smote = SMOTE()

# Aplicar SMOTE al conjunto de entrenamiento para aumentar las instancias de la clase minoritaria
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train_encoded)

# Definir y entrenar el modelo
svm_model = SVC(kernel='rbf', gamma=1e-3, C=10, random_state=42, probability=True)
svm_model.fit(X_train_resampled, y_train_resampled)

svm_model.fit(X_train_resampled, y_train_resampled)
pred_test = svm_model.predict(X_test_scaled)
print(f'Classification report')
print(classification_report(y_test_encoded, pred_test))
cm = confusion_matrix(y_test_encoded, pred_test)
# Visualizar la matriz de confusión con Seaborn
sns.heatmap(cm, annot=True, fmt='d', cmap='PiYG', cbar=False,
xticklabels=['Blue-Green', 'Bluish-Green', 'Green'], yticklabels=['Blue-Green', 'Bluish-Green', 'Green'])
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.title('Matriz de Confusión de Random Forest clases de entrenamiento balanceadas')
plt.show(block=True)

X_train_graph_scaled = X_train_resampled[:,[0, 8]]
X_test_graph_scaled = X_test_scaled[:,[0, 8]]
fig, ax = plt.subplots(figsize=(12, 7))
x = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
y = np.linspace(np.min(X_train_graph_scaled[:,0]), np.max(X_train_graph_scaled[:,0]), 50)
Y, X = np.meshgrid(y, x)
grid = np.vstack([X.ravel(), Y.ravel()]).T

svm_model.fit(X_train_graph_scaled, y_train_resampled)
pred_grid = svm_model.predict(grid)

z=svm_model.predict(np.array([X.ravel(), Y.ravel()]).T).reshape(X.shape)

plt.scatter(grid[:,0], grid[:,1], c=pred_grid, alpha = 0.2)

# Plotting decision regions
scatter_highlight_kwargs = {'s': 120, 'label': 3, 'alpha': 0.7}
plot_decision_regions(np.concatenate((X_train_graph_scaled, X_test_graph_scaled), axis=0),
                      np.concatenate((y_train_resampled, y_test_encoded), axis=0), clf=svm_model, legend=3,
                      colors='skyblue,lightcoral,lightgreen', scatter_kwargs={'s': 120, 'alpha':0.7}, X_highlight=X_test_graph_scaled, scatter_highlight_kwargs=scatter_highlight_kwargs)

# Crear una correspondencia entre los números y los nombres de las clases
correspondencia_clases = {0: 'Blue-Green', 1: 'Bluish-Green', 2: 'Green', 3:'Test data'}

# Personalizar la leyenda
handles, labels = plt.gca().get_legend_handles_labels()

# Crear la leyenda con etiquetas personalizadas
etiquetas_personalizadas = [correspondencia_clases[int(label)] for label in labels]
plt.legend(handles, etiquetas_personalizadas, title="Clases")
plt.title('Plot de regiones de decisión y datos de Random Forest clases de entrenamiento balanceadas')
plt.xlabel('Scores_Aftertaste')
plt.ylabel('Scores_Balance')
plt.show(block=True)
"""************************************************************************************************"""
"""Observaciones pertinentes redactadas en el informe en la sección 7. Anexo"""
"""************************************************************************************************"""